{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1, -0.1]\n",
      "-1\n",
      "1\n",
      "1\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, N):\n",
    "        self.w = list()\n",
    "        for i in range(N):\n",
    "            self.w.append( 0)\n",
    "    def calc(self, x):\n",
    "        res = 0\n",
    "        for i in range(len(self.w)):\n",
    "            res = res + self.w[i] * x[i]\n",
    "        return res\n",
    "    def sign(self, x):\n",
    "        if self.calc(x) > 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "    def learn(self, la, x, y):\n",
    "        if y * self.calc(x) <= 0:\n",
    "            for i in range(len(self.w)):\n",
    "                self.w[i] = self.w[i] + la * y * x[i]\n",
    "    def learning(self, la, T):\n",
    "        for n in range(100):\n",
    "            for t in T:\n",
    "                self.learn(la, t[ 0], t[1])\n",
    "perceptron = Perceptron(2)\n",
    "la = 0.1\n",
    "\n",
    "T = list()\n",
    "T.append([[2,1],1])\n",
    "T.append([[3,2],1])\n",
    "T.append([[4,1],1])\n",
    "T.append([[1,2],-1])\n",
    "T.append([[2,3],-1])\n",
    "T.append([[5,7],-1])\n",
    "perceptron.learning(la,T)\n",
    "print(perceptron.w)\n",
    "\n",
    "print(perceptron.sign([1.5,2]))\n",
    "print(perceptron.sign([3,1.5]))\n",
    "print(perceptron.sign([5,1]))\n",
    "print(perceptron.sign([5,10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9990889488055994\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "class Neuron:\n",
    "    def __init__(self, weights, bias):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "    def feedforward(self, inputs):\n",
    "        total = np.dot(self.weights, inputs) + self.bias\n",
    "        return sigmoid(total)\n",
    "\n",
    "weights = np.array([0,1])\n",
    "bias = 4\n",
    "n = Neuron(weights, bias)\n",
    "x = np.array([2,3])\n",
    "print(n.feedforward(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7216325609518421\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "class OurNeuralNetwork:\n",
    "    '''\n",
    "    –î–∞–Ω–Ω—ã–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏:\n",
    "    -–¥–≤–∞ –≤—Ö–æ–¥–∞\n",
    "    -–¥–≤–∞ –Ω–µ–π—Ä–æ–Ω–∞ –≤ —Å–∫—Ä—ã—Ç—ã—Ö —Å–ª–æ—è—Ö (h1,h2)\n",
    "    -–≤—ã—Ö–æ–¥ (–æ1)\n",
    "    –ù–µ–π—Ä–æ–Ω—ã –∏–º–µ—é—Ç –∏–¥–µ–Ω—Ç–∏—á–Ω—ã–µ –≤–µ—Å–∞ –∏ –ø–æ—Ä–æ–≥–∏:\n",
    "    - w = [0,1]\n",
    "    - b = 0\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        weights = np.array([0,1])\n",
    "        bias = 0\n",
    "        \n",
    "        self.h1 = Neuron(weights, bias)\n",
    "        self.h2 = Neuron(weights, bias)\n",
    "        self.o1 = Neuron(weights, bias)\n",
    "    def feedforward(self, x):\n",
    "        out_h1 = self.h1.feedforward(x)\n",
    "        out_h2 = self.h2.feedforward(x)\n",
    "        \n",
    "        out_o1 = self.o1.feedforward(np.array([out_h1, out_h2]))\n",
    "        return out_o1\n",
    "    \n",
    "network = OurNeuralNetwork()\n",
    "x = np.array([2,3])\n",
    "print(network.feedforward(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, x, y):\n",
    "        self.input = x\n",
    "        self.weights1 = np.random.rand(self.input.shape[1],4)\n",
    "        self.weights2 = np.random.rand(4,1)\n",
    "        self.y = y\n",
    "        self.output = np.zeros(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, x, y):\n",
    "        self.input = x\n",
    "        self.weights1 = np.random.rand(self.input.shape[1],4)\n",
    "        self.weights2 = np.random.rand(4,1)\n",
    "        self.y = y\n",
    "        self.output = np.zeros(y.shape)\n",
    "    def feedforward(self):\n",
    "        self.layer1 = sigmoid(np.dot(self.input, self.weights1))\n",
    "        self.output = sigmoid(np.dot(self.layer1, self.weights2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, x, y):\n",
    "        self.input = x\n",
    "        self.weights1 = np.random.rand(self.input.shape[1],4)\n",
    "        self.weights2 = np.random.rand(4,1)\n",
    "        self.y = y\n",
    "        self.output = np.zeros(y.shape)\n",
    "    def feedforward(self):\n",
    "        self.layer1 = sigmoid(np.dot(self.input, self.weights1))\n",
    "        self.output = sigmoid(np.dot(self.layer1, self.weights2))\n",
    "    def backprop(self):\n",
    "        d_weights2 = np.dot(self.layer1.T, (2*(self.y - self.output) * sigmoid_derivative(self.output)))\n",
    "        d_weights1 = np.dot(self.input.T, (np.dot(2*(self.y - self.output) * sigmoid_derivative(self.output), self.weights2.T) * sigmoid_derivative(self.layer1)))\n",
    "        \n",
    "        self.weights1 += d_weights1\n",
    "        self.weights2 += d_weights2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8151036049051821\n"
     ]
    }
   ],
   "source": [
    "#Task 7.1\n",
    "import numpy as np\n",
    "class OurNeuralNetwork:\n",
    "    \"\"\"\n",
    "    –¥–∞–Ω–Ω—ã–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏:\n",
    "        ‚àí —Ç—Ä–∏ –≤—Ö–æ–¥–∞ (ùë•1,ùë•2,ùë•3);\n",
    "        ‚àí —Ç—Ä–∏ –Ω–µ–π—Ä–æ–Ω–∞ –≤ —Å–∫—Ä—ã—Ç—ã—Ö —Å–ª–æ—è—Ö (‚Ñé1,‚Ñé2,‚Ñé3);\n",
    "        ‚àí –≤—ã—Ö–æ–¥ (ùëú1).\n",
    "    –Ω–µ–π—Ä–æ–Ω—ã –∏–º–µ—é—Ç –∏–¥–µ–Ω—Ç–∏—á–Ω—ã–µ –≤–µ—Å–∞ –∏ –ø–æ—Ä–æ–≥–∏:\n",
    "        ‚àí ùë§ = [0.5,0.5,0.5]\n",
    "        ‚àí ùëè = 0     \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        weights = np.array([0.5,0.5,0.5])\n",
    "        bias = 0\n",
    "        # –∫–ª–∞—Å—Å Neuron –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —Ä–∞–∑–¥–µ–ª–∞\n",
    "        self.h1 = Neuron(weights, bias)\n",
    "        self.h2 = Neuron(weights, bias)\n",
    "        self.h3 = Neuron(weights, bias)\n",
    "        self.o1 = Neuron(weights, bias)\n",
    "    def feedforward(self, x):\n",
    "        out_h1 = self.h1.feedforward(x)\n",
    "        out_h2 = self.h2.feedforward(x)\n",
    "        out_h3 = self.h3.feedforward(x)\n",
    "        # –≤—Ö–æ–¥—ã –¥–ª—è –æ1 - —ç—Ç–æ –≤—ã—Ö–æ–¥—ã h1 –∏ h2 –∏ h3\n",
    "        out_o1 = self.o1.feedforward(np.array([out_h1, out_h2, out_h3]))\n",
    "        return out_o1\n",
    "\n",
    "network = OurNeuralNetwork()\n",
    "x = np.array([2,3,4])\n",
    "print(network.feedforward(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8671195555587996\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "class OurNeuralNetwork:\n",
    "    \"\"\"\n",
    "    –¥–∞–Ω–Ω—ã–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏:\n",
    "        - –¥–≤–∞ –≤—Ö–æ–¥–∞\n",
    "        - –¥–≤–∞ –Ω–µ–π—Ä–æ–Ω–∞ –≤ —Å–∫—Ä—ã—Ç—ã—Ö —Å–ª–æ—è—Ö (h1, h2)\n",
    "        - –≤—ã—Ö–æ–¥ (–æ1, o2)\n",
    "    –Ω–µ–π—Ä–æ–Ω—ã –∏–º–µ—é—Ç –∏–¥–µ–Ω—Ç–∏—á–Ω—ã–µ –≤–µ—Å–∞ –∏ –ø–æ—Ä–æ–≥–∏:\n",
    "        - w = [1,0]\n",
    "        - b = 1\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        weights = np.array([1,0])\n",
    "        bias = 1\n",
    "        # –∫–ª–∞—Å—Å Neuron –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —Ä–∞–∑–¥–µ–ª–∞\n",
    "        self.h1 = Neuron(weights, bias)\n",
    "        self.h2 = Neuron(weights, bias)\n",
    "        self.o1 = Neuron(weights, bias)\n",
    "        self.o2 = Neuron(weights, bias)\n",
    "        self.o = Neuron(weights, bias)\n",
    "    def feedforward(self, x):\n",
    "        out_h1 = self.h1.feedforward(x)\n",
    "        out_h2 = self.h2.feedforward(x)\n",
    "        # –≤—Ö–æ–¥—ã –¥–ª—è –æ1 - —ç—Ç–æ –≤—ã—Ö–æ–¥—ã h1 –∏ h2\n",
    "        out_o1 = self.o1.feedforward(np.array([out_h1, out_h2]))\n",
    "        out_o2 = self.o2.feedforward(np.array([out_h2, out_h1]))\n",
    "        out_o = self.o.feedforward(np.array([out_o2, out_o1]))\n",
    "        return out_o\n",
    "\n",
    "network = OurNeuralNetwork()\n",
    "x = np.array([2,3])\n",
    "print(network.feedforward(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 7.2\n",
    "from cmath import tanh\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, x, y):\n",
    "        self.input    = x\n",
    "        self.weights1 = np.random.rand(self.input.shape[1],4)\n",
    "        self.weights2 = np.random.rand(4,1)\n",
    "        self.y        = y\n",
    "        self.output   = np.zeros(y.shape)\n",
    "\n",
    "    def tanh_derivative(self, x):\n",
    "        return 1 - tanh(x) * tanh(x)\n",
    "    def feedforward(self):\n",
    "        self.layer1 = tanh(np.dot(self.input, self.weights1))\n",
    "        self.output = tanh(np.dot(self.layer1, self.weights2))\n",
    "    def backprop(self):\n",
    "        # –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø—Ä–∞–≤–∏–ª–∞ —Ü–µ–ø–∏ –¥–ª—è –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –ø–æ –≤–µ—Å—É2 –∏ –≤–µ—Å—É1\n",
    "        d_weights2 = np.dot(self.layer1.T, (2*(self.y - self.output) * self.tanh_derivative(self.output)))\n",
    "        d_weights1 = np.dot(self.input.T, (np.dot(2*(self.y - self.output) * self.tanh_derivative(self.output), self.weights2.T) * self.tanh_derivative(self.layer1)))\n",
    "        # –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤–µ—Å–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–Ω–æ–π (–Ω–∞–∫–ª–æ–Ω–∞) —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å\n",
    "        self.weights1 += d_weights1\n",
    "        self.weights2 += d_weights2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmath import tanh\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, x, y):\n",
    "        self.input    = x\n",
    "        self.weights1 = np.random.rand(self.input.shape[1],4)\n",
    "        self.weights2 = np.random.rand(4,1)\n",
    "        self.y        = y\n",
    "        self.output   = np.zeros(y.shape)\n",
    "\n",
    "    def ReLU_derivative(self, x):\n",
    "        if x >= 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    def feedforward(self):\n",
    "        self.layer1 = max(0, np.dot(self.input, self.weights1))\n",
    "        self.output = max(0, np.dot(self.layer1, self.weights2))\n",
    "    def backprop(self):\n",
    "        # –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø—Ä–∞–≤–∏–ª–∞ —Ü–µ–ø–∏ –¥–ª—è –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –ø–æ –≤–µ—Å—É2 –∏ –≤–µ—Å—É1\n",
    "        d_weights2 = np.dot(self.layer1.T, (2*(self.y - self.output) * self.ReLU_derivative(self.output)))\n",
    "        d_weights1 = np.dot(self.input.T, (np.dot(2*(self.y - self.output) * self.ReLU_derivative(self.output), self.weights2.T) * self.ReLU_derivative(self.layer1)))\n",
    "        # –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤–µ—Å–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–Ω–æ–π (–Ω–∞–∫–ª–æ–Ω–∞) —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å\n",
    "        self.weights1 += d_weights1\n",
    "        self.weights2 += d_weights2   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Sizes :  (1797, 64) (1797,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits, load_boston\n",
    "\n",
    "digits = load_digits()\n",
    "X_digits, Y_digits = digits.data, digits.target\n",
    "print('Dataset Sizes : ', X_digits.shape, Y_digits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Sizes :  (506, 13) (506,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
    "target = raw_df.values[1::2, 2]\n",
    "X_boston, Y_boston = data, target\n",
    "print('Dataset Sizes : ', X_boston.shape, Y_boston.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Test Sizes :  (1437, 64) (360, 64) (1437,) (360,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_digits, Y_digits, train_size = 0.80, test_size=0.20, stratify=Y_digits, random_state=123)\n",
    "print('Train/Test Sizes : ', X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(random_state=123)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp_classifier = MLPClassifier(random_state=123)\n",
    "mlp_classifier.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 9 9 6 1 6 6 9 8 7 4 2 1 4 3]\n",
      "[5 9 9 6 1 6 6 9 8 7 4 2 1 4 3]\n",
      "Test Accuracy : 0.983\n",
      "Training Accuracy : 1.000\n"
     ]
    }
   ],
   "source": [
    "Y_preds = mlp_classifier.predict(X_test)\n",
    "\n",
    "print(Y_preds[:15])\n",
    "print(Y_test[:15])\n",
    "\n",
    "print('Test Accuracy : %.3f'%mlp_classifier.score(X_test, Y_test))\n",
    "\n",
    "print('Training Accuracy : %.3f'%mlp_classifier.score(X_train, Y_train))\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(Y_test, Y_preds):\n",
    "    conf_mat = confusion_matrix(Y_test, Y_preds)\n",
    "    \n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    plt.matshow(conf_mat, cmap=plt.cm.Blues, fignum=1)\n",
    "    plt.yticks(range(10), range(10))\n",
    "    plt.xticks(range(10), range(10))\n",
    "    plt.colorbar();\n",
    "    for i in range(10):\n",
    "        for j in range(10):\n",
    "            plt.text(i-0.2, j+0.1, str(conf_mat[j,i]), color='tab:red')\n",
    "plot_confusion_matrix(Y_test, mlp_classifier.predict(X_test))   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss :  0.0034728684994180603\n",
      "Number of Coefs :  2\n",
      "Number of Intercepts :  2\n",
      "Number of Interations for Which Estimator Ran :  125\n",
      "Name of Output Layer Activation Function :  softmax\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss : \", mlp_classifier.loss_)\n",
    "print(\"Number of Coefs : \", len(mlp_classifier.coefs_))\n",
    "print(\"Number of Intercepts : \", len(mlp_classifier.intercepts_))\n",
    "print(\"Number of Interations for Which Estimator Ran : \", mlp_classifier.n_iter_)\n",
    "print(\"Name of Output Layer Activation Function : \", mlp_classifier.out_activation_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Test Sizes :  (404, 13) (102, 13) (404,) (102,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_boston, Y_boston, train_size=0.80, test_size=0.20, random_state=123)\n",
    "print('Train/Test Sizes : ', X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(random_state=123)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "mlp_regressor = MLPRegressor(random_state=123)\n",
    "mlp_regressor.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7.32543601 24.33417853 32.46700507 15.19086054 25.6749167  25.07797685\n",
      " 27.20985668  2.62269853 15.25691994 28.02637784]\n",
      "[15.  26.6 45.4 20.8 34.9 21.9 28.7  7.2 20.  32.2]\n",
      "Test R^2 Score : 0.462\n",
      "Training R^2 Score : 0.510\n"
     ]
    }
   ],
   "source": [
    "Y_preds = mlp_regressor.predict(X_test)\n",
    "\n",
    "print(Y_preds[:10])\n",
    "print(Y_test[:10])\n",
    "\n",
    "print('Test R^2 Score : %.3f'%mlp_regressor.score(X_test, Y_test))\n",
    "\n",
    "print('Training R^2 Score : %.3f'%mlp_regressor.score(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss :  28.538174061119584\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss : \", mlp_regressor.loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Coefs :  2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(13, 100), (100, 1)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of Coefs : \", len(mlp_regressor.coefs_))\n",
    "[weights.shape for weights in mlp_regressor.coefs_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Iterations for Which Estimator Ran :  130\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Iterations for Which Estimator Ran : \", mlp_regressor.n_iter_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of Output Layer Activation Function :  identity\n"
     ]
    }
   ],
   "source": [
    "print(\"Name of Output Layer Activation Function : \", mlp_regressor.out_activation_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(max_iter=670, random_state=123)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = r'https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv'\n",
    "\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.iloc[:,:-1],    # –≤—Å–µ –∫–æ–ª–æ–Ω–∫–∏ –∫—Ä–æ–º–µ –ø–æ—Å–ª–µ–¥–Ω–µ–π - –≤ –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
    "    data.iloc[:,-1], # –ø–æ—Å–ª–µ–¥–Ω—é—é –≤ —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é (–∫–ª–∞—Å—Å)\n",
    "    test_size = 0.20 # —Ä–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏ 20%\n",
    ")\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp_classifier = MLPClassifier(random_state=123, max_iter =670)\n",
    "mlp_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Setosa' 'Setosa' 'Versicolor' 'Virginica' 'Versicolor' 'Virginica'\n",
      " 'Versicolor' 'Versicolor' 'Versicolor' 'Virginica' 'Virginica' 'Setosa'\n",
      " 'Setosa' 'Versicolor' 'Setosa']\n",
      "11         Setosa\n",
      "42         Setosa\n",
      "85     Versicolor\n",
      "146     Virginica\n",
      "74     Versicolor\n",
      "122     Virginica\n",
      "56     Versicolor\n",
      "67     Versicolor\n",
      "53     Versicolor\n",
      "113     Virginica\n",
      "128     Virginica\n",
      "12         Setosa\n",
      "39         Setosa\n",
      "50     Versicolor\n",
      "32         Setosa\n",
      "Name: variety, dtype: object\n",
      "Test Accurancy: 1.000\n",
      "Training Accurancy: 0.967\n"
     ]
    }
   ],
   "source": [
    "Y_preds = mlp_classifier.predict(X_test)\n",
    "\n",
    "print(Y_preds[:15])\n",
    "print(y_test[:15])\n",
    "## –º–º—Ç–µ–¥–æ Score –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Ç–æ—á–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏\n",
    "print('Test Accurancy: %.3f'%mlp_classifier.score(X_test, y_test))\n",
    "print('Training Accurancy: %.3f'%mlp_classifier.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.08604574939150034\n",
      "Number of coefs:  2\n",
      "Number of intercepts:  2\n",
      "Number of iterations for which estimator ran:  657\n",
      "Name of output layer activation function:  softmax\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss: \", mlp_classifier.loss_)\n",
    "print(\"Number of coefs: \", len(mlp_classifier.coefs_))\n",
    "print(\"Number of intercepts: \", len(mlp_classifier.intercepts_))\n",
    "print(\"Number of iterations for which estimator ran: \", mlp_classifier.n_iter_)\n",
    "print(\"Name of output layer activation function: \", mlp_classifier.out_activation_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 1) (6, 1) (24,) (6,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(max_iter=100000, random_state=123)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = r'https://raw.githubusercontent.com/AnnaShestova/salary-years-simple-linear-regression/master/Salary_Data.csv'\n",
    "\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.iloc[:,:-1].values,    # –≤—Å–µ –∫–æ–ª–æ–Ω–∫–∏ –∫—Ä–æ–º–µ –ø–æ—Å–ª–µ–¥–Ω–µ–π - –≤ –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
    "    data.iloc[:,-1].values, # –ø–æ—Å–ª–µ–¥–Ω—é—é –≤ —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é (–∫–ª–∞—Å—Å)\n",
    "    test_size = 0.20, # —Ä–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏ 20%\n",
    "    random_state=123\n",
    ")\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "mlp_regressor = MLPRegressor(random_state=123, max_iter =100000)\n",
    "mlp_regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 55265.2045971  126554.5591937   52335.80522199 116782.59147446\n",
      "  55265.2045971  117759.05793283]\n",
      "[ 54445. 121872.  56642. 116969.  64445. 112635.]\n",
      "Test R^2: 0.971\n",
      "Training R^2: 0.948\n"
     ]
    }
   ],
   "source": [
    "Y_preds = mlp_regressor.predict(X_test)\n",
    "\n",
    "print(Y_preds[:10])\n",
    "print(y_test[:10])\n",
    "print('Test R^2: %.3f'%mlp_regressor.score(X_test, y_test))\n",
    "print('Training R^2: %.3f'%mlp_regressor.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  16873681.689960096\n",
      "Number of coefs:  2\n",
      "Number of intercepts:  2\n",
      "Number of iterations for which estimator ran:  30344\n",
      "Name of output layer activation function:  identity\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss: \", mlp_regressor.loss_)\n",
    "print(\"Number of coefs: \", len(mlp_regressor.coefs_))\n",
    "print(\"Number of intercepts: \", len(mlp_regressor.intercepts_))\n",
    "print(\"Number of iterations for which estimator ran: \", mlp_regressor.n_iter_)\n",
    "print(\"Name of output layer activation function: \", mlp_regressor.out_activation_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
